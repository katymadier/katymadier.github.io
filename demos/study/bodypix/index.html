<html lang="en" dir="ltr">
  <head>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta charset="UTF-8">
    <title>BodyPix Demo</title>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/body-pix"></script>
    <script src="https://aframe.io/releases/0.8.0/aframe.min.js"></script>
    <script src="https://rawgit.com/feiss/aframe-environment-component/master/dist/aframe-environment-component.min.js"></script>
    <style>
     body {
       margin: 0;
       width: 100%;
     }
     @media only screen and (max-width: 850px) {
       a-scene {
         width: 100%;
         height: 100%;
         overflow: hidden;
       }
     }
    </style>
  </head>

  <body>
    <a-scene stats environment>
      <a-assets>
         <video id="video" crossorigin="anonymous" ></video>
         <canvas id="canvas"></canvas>
      </a-assets>
      <a-plane position="-2 2 -4" rotation="0 0 0" width="4" height="4" material="src:#canvas"></a-plane>
      <a-text id="info" style='display:none'></a-text>
      <a-video material="visible:false" src="#video" width="2" height="2" webkit-playsinline playsinline style=" -moz-transform: scaleX(-1);
        -o-transform: scaleX(-1);
        -webkit-transform: scaleX(-1);
        transform: scaleX(-1);
        display: none;
        "></a-video>
    </a-scene>
    <script type="module">

    // code for body tracking remixed for VR from Tensorflow & BodyPix https://github.com/tensorflow/tfjs-models/tree/master/body-pix#person-segmentation

    const video = document.getElementById('video');
    const canvas = document.getElementById('canvas');
    const videoWidth = 400;
    const videoHeight = 400;
    video.width = videoWidth;
    video.height = videoHeight;

    const opacity = 1;
    const outputStride = 8;
    const segmentationThreshold = .8;
    const flipHorizontally = true;
    const maskBlurAmount = 0;
    const pixelCellWidth = 10.0;
    const warm = [
      [110, 64, 170], [106, 72, 183], [100, 81, 196], [92, 91, 206],
      [84, 101, 214], [75, 113, 221], [66, 125, 224], [56, 138, 226],
      [48, 150, 224], [40, 163, 220], [33, 176, 214], [29, 188, 205],
      [26, 199, 194], [26, 210, 182], [28, 219, 169], [33, 227, 155],
      [41, 234, 141], [51, 240, 128], [64, 243, 116], [79, 246, 105],
      [96, 247, 97],  [115, 246, 91], [134, 245, 88], [155, 243, 88]
    ];

    function isAndroid() {
      return /Android/i.test(navigator.userAgent);
    }
    function isiOS() {
      return /iPhone|iPad|iPod/i.test(navigator.userAgent);
    }
    function isMobile() {
      return isAndroid() || isiOS();
    }

    async function setupCamera() {
      // console.log("running camera set up")
      if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
        throw new Error(
            'Browser API navigator.mediaDevices.getUserMedia not available');
      }

      const mobile = isMobile();
      const stream = await navigator.mediaDevices.getUserMedia({
        'audio': false,
        'video': {
          facingMode: 'environment',
          width: mobile ? undefined : videoWidth,
          height: mobile ? undefined : videoHeight,
        },
      });
      video.srcObject = stream;

      return new Promise((resolve) => {
        video.onloadedmetadata = () => {
          // console.log("resolving video")
          resolve(video);
        };
      });

    }
    function segmentBodyInRealTime() {
      async function bodySegmentationFrame() {
        const net = await bodyPix.load(.25);
        const partSegmentation = await net.estimatePartSegmentation(
            video, outputStride, segmentationThreshold);
        // console.log("segmentation", partSegmentation)

        // 1 is the body, 0 is not the body, -1 is not found

        // deconstruct this function to find the blocks being generated.
        const coloredPartImageData = bodyPix.toColoredPartImageData(
            partSegmentation, warm);

        bodyPix.drawPixelatedMask(
            canvas, video, coloredPartImageData, opacity,
            maskBlurAmount, flipHorizontally, pixelCellWidth);

        requestAnimationFrame(bodySegmentationFrame);
      }

      bodySegmentationFrame();
    }
    async function loadVideo() {
      try {
        const video = await setupCamera();
      } catch (e) {
        let info = document.getElementById('info');
        info.value = 'this browser does not support video capture,' +
            'or this device does not have a camera';
        info.style.display = 'block';
        throw e;
      }
      // console.log("playing video")
      video.play();
      return video
    }

    async function bindPage() {
      // console.log("binding page")
      await loadVideo();
      segmentBodyInRealTime();
    }
    navigator.getUserMedia = navigator.getUserMedia ||
        navigator.webkitGetUserMedia || navigator.mozGetUserMedia;

    bindPage();

    </script>
</body>
</html>
